---
title: "R Notebook"
output: html_notebook
params:
  clearbit_api_key: !r Sys.getenv("API_KEY_CLEARBIT")
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(domaintools)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(here)
library(httr)
library(igraph)
library(lubridate)
library(readr)
library(scales)
library(stringr)
library(tidyr)
library(TTR)
library(urltools)
library(visNetwork)
```

# Overview

Previous work considered different ways to use the commit log to learn about open source community activities. This notebook attempts to abstract common tasks for this analysis so it can be applied to several repositories of interest. Currently analysis is only being done at the repository level. Future work will look at organization level activity.

Note that comparing repositories and projects is difficult because each has their differences in terms of workflow and structure. This current version of the analysis does not take those differences into consideration but future work will.

# Git Repository

# Setup Instructions

Clone repositories into the repos folder. Currently hard-coding, will use another method in the future. While there are better ways to go about this, a quick web search turned up the following "top 10" list and it fit with requests I've gotten over the months. ^[[Packtpub's Top 10 Deep Learning Frameworks (Updated December 2017)](https://datahub.packtpub.com/deep-learning/top-10-deep-learning-frameworks/)]

```{r repositories}

repos <- c(
  "pair-code/deeplearnjs",
  "microsoft/cntk",
  "bvlc/caffe",
  "tensorflow/tensorflow",
  "aws/sagemaker-python-sdk",
  "intel-analytics/BigDL",
  "apache/incubator-mxnet",
  "deeplearning4j/deeplearning4j",
  "pytorch/pytorch",
  "keras-team/keras",
  "apple/coremltools",
  "h2oai/h2o-3"
)

model_support_repos <- c(
  "tensorflow/tensor2tensor",
  "apple/coremltools"
)

```


```{r git_clone, eval=FALSE}
# Clone the repo into the data directory for this project - set eval to FALSE so we don't do this each time

for (repo in repos) {
  git_url <- paste0("git@github.com:", repo, ".git")
  repo_short <- str_split(repo, "/")[[1]][2]
  dir.create(here::here("repos"), "/", repo_short)
  git_cmd <- paste0("git clone ", git_url, " ", here::here("repos"), "/", repo_short, "/repo")
  print(git_cmd)
  system(git_cmd)
}

```

This notebook sets the SHA used for the analysis as a parameter to ensure reproducibility. If you want to run this against the latest changes, update the SHA in the parameters to the latest one in your local repository.

# Get Git Commit Log

```{r git_log, eval=FALSE}

for (repo in repos) {
  repo_short <- str_split(repo, "/")[[1]][2]
  
  repo_path <- here::here("repos", repo_short, "repo")
  gitlog_file <- paste0("gitlog_", repo_short, ".txt")
  
  git_log_cmd <- paste0('cd ', repo_path,
                     '; git log ', 
                     ' --no-merges ',
                     ' --date=short --pretty=tformat:"%ad|%an|%ae|%cd|%cn|%ce|%h" > ', 
                     "../", gitlog_file)
  print(git_log_cmd)
  system(git_log_cmd)
}
```

# Read in the Commit Logs

```{r gitlog_raw, eval=FALSE}

gitlog_raw <- data_frame()

for (repo in repos) {
  repo_short <- str_split(repo, "/")[[1]][2]
  gitlog_path <- here::here("repos", repo_short, paste0("gitlog_", repo_short, ".txt"))

  gitlog_repo <- read_delim(gitlog_path,
                         delim = "|", quote="",
                         col_names=c("author_date", "author_name", "author_email", 
                                   "committer_date", "committer_name", "committer_email", 
                                   "sha"))
  gitlog_repo <- gitlog_repo %>% mutate(repo=repo, repo_short=repo_short)
  print(repo_short)
  gitlog_raw <- bind_rows(gitlog_repo, gitlog_raw)
}

saveRDS(gitlog_raw, "dl-frameworks-commit-log_gitlog_raw.Rds")
```

## Create Time Intervals

```{r gitlog_dates, eval=FALSE}
gitlog_raw <- readRDS("dl-frameworks-commit-log_gitlog_raw.Rds")

# fix names and emails to be all lowercase
gitlog_commits_dates <- gitlog_raw %>%
  mutate(
         author_date=as.Date(author_date, tz="UTC"),
         committer_date=as.Date(committer_date, tz="UTC")
    ) %>% 
  mutate(
    commit_date=ymd(committer_date),
    commit_year=floor_date(commit_date, "year"),
    commit_halfyear=floor_date(commit_date, "halfyear"),
    commit_quarter=floor_date(commit_date, "quarter"),
    commit_month=floor_date(commit_date, "month"),
    commit_bimonth=floor_date(commit_date, "bimonth"),
    commit_week=floor_date(commit_date, "week")
  )
```

## Extract Email Domains

```{r gitlog_email_domains, eval=FALSE}

gitlog_commits <- gitlog_commits_dates %>% 
  mutate(
         author_name=str_to_lower(author_name),
         author_email=str_to_lower(author_email),
         committer_name=str_to_lower(committer_name),
         committer_email=str_to_lower(committer_email)
    ) %>% 
  separate(author_email, c("author_username", "author_host"), sep="@", remove=FALSE) %>%
  separate(committer_email, c("committer_username", "committer_host"), sep="@", remove=FALSE) %>%
  mutate(
    author_domain = suffix_extract(author_host)$domain,
    author_suffix = suffix_extract(author_host)$suffix,
    committer_domain = suffix_extract(committer_host)$domain,
    committer_suffix = suffix_extract(committer_host)$suffix,
    )

```

```{r export_gitlog_commits, eval=FALSE}
saveRDS(gitlog_commits, "dl-frameworks-commit-log_gitlog_commits.Rds")
```

# Dedupe using iGraph

Normally I would argue this isn't worth it, but at some point I want to look for the same author committing to multiple repos and the group_id will be useful for that.

```{r committers_lookup, eval=FALSE, }
gitlog_commits <- readRDS("dl-frameworks-commit-log_gitlog_commits.Rds")

gh_committers_by_email <- gitlog_commits %>%
  rename(name=committer_name, email=committer_email) %>%
  arrange(desc(commit_date)) %>%
  group_by(email, name) %>%
  summarise(last_commit=max(commit_date)) %>%
  arrange(desc(last_commit)) 

gh_committers_join1 <- gh_committers_by_email %>%
  inner_join(gh_committers_by_email %>% select(name, email) %>% rename(name2=name), "email") %>%
  unique()

gh_committers_join <- gh_committers_join1 %>%
  inner_join(gh_committers_join1 %>% select(name, email) %>% rename(email2=email), "name") %>%
  unique()

rm(gh_committers_join1)

```

```{r authors_lookup, eval=FALSE}

# group commits by email address and name
gh_authors_by_email <- gitlog_commits %>%
  rename(name=author_name, email=author_email) %>%
  arrange(desc(commit_date)) %>%
  group_by(email, name) %>%
  summarise(num_commits = n(), 
            last_commit=max(commit_date)) %>%
  arrange(desc(last_commit))

# join on name to show emails tied to the same names
gh_authors_join1 <- gh_authors_by_email %>%
  inner_join(gh_authors_by_email %>% select(name, email) %>% rename(name2=name), "email") %>%
  unique()

# join on email to show names tied to the same emails
gh_authors_join <- gh_authors_join1 %>%
  inner_join(gh_authors_join1 %>% select(name, email) %>% rename(email2=email), "name") %>%
  unique()

rm(gh_authors_join1)

```

```{r join_emails, eval=FALSE, }
gh_emails <- bind_rows(gh_authors_join %>% select(email, email2), gh_committers_join %>% select(email, email2))
gh_emails <- gh_emails %>% ungroup() %>% unique()
```

```{r emails_graph, eval=FALSE, warning=FALSE}

# this might need to be directed in the future based on commit dates
gh_emails_graph_big <- graph_from_data_frame(gh_emails,
                                             directed=FALSE)

E(gh_emails_graph_big)$weight <- 1
gh_emails_graph <- simplify(gh_emails_graph_big, 
                            edge.attr.comb=list(
                              weight = "sum", 
                              transaction_amount = "sum", 
                              function(x)length(x))
                            )

# identify clusters
gh_emails_networks <- clusters(as.undirected(gh_emails_graph))
V(gh_emails_graph)$network <- gh_emails_networks$membership

# extract vertices
gh_emails_nodes_vert <- get.data.frame(gh_emails_graph, what="vertices")

# create nodes with fields used by Visnetwork for plotting
gh_emails_nodes <- data.frame(id = gh_emails_nodes_vert$name,
                              title = gh_emails_nodes_vert$name, 
                              group = gh_emails_nodes_vert$network)
gh_emails_nodes <- gh_emails_nodes[order(gh_emails_nodes$id, decreasing = F),]

# extract edges
gh_emails_edges <- get.data.frame(gh_emails_graph, what="edges")[1:2]

# remove data structures we no longer need
rm(gh_committers_emails_graph, gh_emails_graph, gh_emails_networks, gh_emails_nodes_pre)

# join by committer email address with git log data to get the clusters
gitlog_networks <- gitlog_commits %>% 
  ungroup() %>%
  inner_join(gh_emails_nodes %>% 
               select(id, group) %>% 
               rename(committer_group=group), 
             by=c("committer_email"="id"))

# join by author
gitlog_networks <- gitlog_networks %>% 
  ungroup() %>%
  inner_join(gh_emails_nodes %>% 
               select(id, group) %>% 
               rename(author_group=group), 
             by=c("author_email"="id"))

saveRDS(gitlog_networks, "dl-frameworks_network.Rds")

paste("identified", max(gitlog_networks$committer_group),"unique committers from", n_distinct(gh_emails$email),"emails")
paste("identified", max(gitlog_networks$author_group),"unique authors from", n_distinct(gh_emails$email),"emails")

```

# Dominant Email Identification

```{r stocks_lookup, eval=FALSE}
stock <- stockSymbols(exchange = c("AMEX", "NASDAQ", "NYSE"), sort.by = c("Exchange", "Symbol"), quiet = FALSE)
saveRDS(stock, "stocks.RDS")
```

```{r add_new_repo, warning=FALSE, eval=FALSE}

# run repo etc above, rebuild network
gitlog_networks <- readRDS("dl-frameworks_network.Rds")

# make the domain list
gitlog_networks_domains <- bind_rows(gitlog_networks %>% 
                                       select(committer_host, committer_domain) %>% 
                                       rename(host=committer_host, domain=committer_domain), 
                                     gitlog_networks %>% 
                                       select(author_host, author_domain) %>%
                                       rename(host=author_host, domain=author_domain)
                                     ) %>% unique()

gitlog_networks_domains <- gitlog_networks_domains %>% 
  group_by(domain) %>% 
  summarise(host=first(host))

# check which ones we already have

# current clean list
clearbit <- readRDS("dl-frameworks_domain_info_clean.Rds")

# find ones we don't have

# clearbit_unidentified <- gitlog_networks_domains %>%
#   anti_join(clearbit, by=c("host"="host_looked_up"))

clearbit <- read_rds("dl-frameworks_domain_info.Rds")
clearbit_unidentified <- clearbit %>% filter(error.type=="queued") %>% select(host_looked_up)

# hit up clearbit for the domains we haven't tried to identify already

clearbit_new <- data_frame()
for (n in 1:nrow(clearbit_unidentified)) {
  paste(clearbit_unidentified$host[n])
  clearbit_url <- paste0("https://company.clearbit.com/v2/companies/find?domain=", clearbit_unidentified$host[n])
  clearbit_get <- GET(clearbit_url, add_headers(Authorization = clearbit_auth))
  if (clearbit_get$status_code == 422) {
    next()
  }
  clearbit_json <- fromJSON(content(clearbit_get, as = "text"), flatten=TRUE)
  clearbit_json$domainAliases = paste(clearbit_json$domainAliases, collapse=",")
  clearbit_json$tags = paste(clearbit_json$tags, collapse=",")
  clearbit_df <-  clearbit_json %>% unlist() %>% as.data.frame.list()
  
  clearbit_df <- clearbit_df %>% 
    mutate(row=n, 
           host_looked_up=clearbit_unidentified$host[n])
  
  write_rds(clearbit_df, paste0("domain_info/clearbit_df_", clearbit_unidentified$domain[n],".Rds"))
  clearbit_new <- bind_rows(clearbit_new, clearbit_df)
}

clearbit <- bind_rows(clearbit_new, clearbit)
saveRDS(clearbit, "dl-frameworks_domain_info.Rds")

```



```{r identify_big_orgs, warning=FALSE, eval=FALSE}
gitlog_networks <- readRDS("dl-frameworks_network.Rds")

# TODO DO NOT COMMIT
clearbit_auth <- paste("Bearer", "")

# make a list of domains
gitlog_networks_domains <- bind_rows(gitlog_networks %>% 
                                       select(committer_host, committer_domain) %>% 
                                       rename(host=committer_host, domain=committer_domain), 
                                     gitlog_networks %>% 
                                       select(author_host, author_domain) %>%
                                       rename(host=author_host, domain=author_domain)
                                     ) %>% unique()

gitlog_networks_domains <- gitlog_networks_domains %>% 
  group_by(domain) %>% 
  summarise(host=first(host))

clearbit <- data_frame()
for (n in 1:nrow(gitlog_networks_domains)) {
  paste(gitlog_networks_domains$host[n])
  clearbit_url <- paste0("https://company.clearbit.com/v2/companies/find?domain=", gitlog_networks_domains$host[n])
  clearbit_get <- GET(clearbit_url, add_headers(Authorization = clearbit_auth))
  if (clearbit_get$status_code == 422) {
    next()
  }
  clearbit_json <- fromJSON(content(clearbit_get, as = "text"), flatten=TRUE)
  clearbit_json$domainAliases = paste(clearbit_json$domainAliases, collapse=",")
  clearbit_json$tags = paste(clearbit_json$tags, collapse=",")
  clearbit_df <-  clearbit_json %>% unlist() %>% as.data.frame.list()
  
  clearbit_df <- clearbit_df %>% 
    mutate(row=n, 
           host_looked_up=gitlog_networks_domains$host[n])
  
  write_rds(clearbit_df, paste0("domain_info/clearbit_df_", gitlog_networks_domains$domain[n],".Rds"))
  clearbit <- bind_rows(clearbit, clearbit_df)
}

saveRDS(clearbit, "dl-frameworks_domain_info.Rds")
```

```{r clean_domain_lookup, eval=FALSE}

# some of the company data in here isn't quite right (public companies listed as "private" and no ticker)
clearbit <- read_rds("dl-frameworks_domain_info.Rds")
stocks <- read_rds("stocks.Rds")

# which companies have ticker symbols that got missed by Clearbit

clearbit_stocks <- clearbit %>%
  select(id, name, legalName, domain, domainAliases, 
         category.sector, category.industryGroup, category.subIndustry, category.naicsCode, category.sicCode,
         location, emailProvider, 
         metrics.alexaUsRank, metrics.alexaGlobalRank, metrics.employees, metrics.annualRevenue,
         row, host_looked_up, ticker, type, foundedYear) %>%
  left_join(stocks %>% select(Name, Symbol, Sector, Industry), by=c("legalName"="Name"))

knitr::kable(clearbit_stocks %>% 
  filter(!is.na(legalName) & type !="public" & !is.na(Symbol)) %>% 
  select(legalName, Symbol, ticker, type), 
  format="pandoc", padding = 2,
  format.args = list(border = "1"),
  caption="Public Companies Mis-typed by Clearbit")

knitr::kable(clearbit_stocks %>% 
  filter(Symbol != ticker | (is.na(ticker) & !is.na(Symbol))) %>% 
  select(legalName, Symbol, ticker, type), 
  format="pandoc", padding = 2,
  format.args = list(border = "1"),
  caption="Public Companies Mis-typed by Clearbit")

# if clearbit didn't identify a ticker but we found one in stocks, update ticker
clearbit_stocks <- clearbit_stocks %>%
  mutate(
    ticker=ifelse(!is.na(legalName) & type !="public" & !is.na(Symbol), Symbol, ticker),
    type=ifelse(!is.na(ticker), "public", type)
  ) %>% # consolidate multiple exchanges
  select(-Symbol) %>%
  unique()

# fix numerics that are chars

clearbit_stocks <- clearbit_stocks %>%
  mutate(
    metrics.alexaUsRank = as.numeric(as.character(metrics.alexaUsRank)),
    metrics.alexaGlobalRank = as.numeric(as.character(metrics.alexaGlobalRank)),
    metrics.employees = as.numeric(as.character(metrics.employees)),
    metrics.annualRevenue = as.numeric(as.character(metrics.annualRevenue))
    )

write_rds(clearbit_stocks, "dl-frameworks_domain_info_clean.Rds")
```

```{r link_domains_with_commits, eval=FALSE}

clearbit <- readRDS("dl-frameworks_domain_info_clean.Rds")
gitlog_networks <- readRDS("dl-frameworks_network.Rds")

domain_company_type <- clearbit %>% 
  filter(! is.na(id)) %>% 
  select(domain, type, name, metrics.employees) %>%
  rename(host=domain, company_type=type, company_name=name) %>%
  mutate(domain=suffix_extract(host)$domain)

# join by committer email
gitlog_networks_org <- gitlog_networks %>% 
  left_join(domain_company_type %>% 
              select(-host) %>%
              rename(committer_domain=domain, 
                     committer_company_name=company_name, 
                     committer_company_type=company_type, 
                     committer_company_employees=metrics.employees)) %>%
  unique()

# join by author email 
gitlog_networks_org <- gitlog_networks_org %>% 
  left_join(domain_company_type %>% 
              select(-host) %>%
              rename(author_domain=domain, 
                     author_company_name=company_name, 
                     author_company_type=company_type,
                     author_company_employees=metrics.employees)) %>%
  unique()


saveRDS(gitlog_networks_org, "dl-frameworks-commit-log_domain_info.Rds")

```

```{r author_company_summary, fig.height=10, fig.width=12}

gitlog_networks_org <-readRDS("dl-frameworks-commit-log_domain_info.Rds")
gitlog_networks_feb <- gitlog_networks_org %>% filter(commit_month > "2017-12-01" & commit_month < "2018-03-01")
saveRDS(gitlog_networks_feb, "dl-frameworks-network-public-companies_Feb2018.Rds")

author_company_type_summary <- gitlog_networks_feb %>%
  ungroup() %>%
  group_by(repo_short) %>%
  mutate(total_authors=n_distinct(author_group)) %>%
  group_by(author_group) %>%
  mutate(latest_email = author_email[which.max(commit_date)],
         author_latest_company=author_company_name[which.max(commit_date)],
         author_latest_company_type=author_company_type[which.max(commit_date)],
         author_latest_company_employees=author_company_employees[which.max(commit_date)]) %>%
  group_by(repo_short, author_latest_company_type) %>%
  summarise(num_authors=n_distinct(author_group),
            pct_authors=round(num_authors/first(total_authors), 2),
            author_company_employees=first(author_company_employees))

author_company_summary <- gitlog_networks_feb %>%
  group_by(repo_short, commit_month) %>%
  mutate(total_authors=n_distinct(author_group)) %>%
  group_by(author_group) %>%
  mutate(latest_email = author_email[which.max(commit_date)],
         author_latest_company=author_company_name[which.max(commit_date)],
         author_latest_company_type=author_company_type[which.max(commit_date)],
         author_latest_company_employees=author_company_employees[which.max(commit_date)]) %>%
  group_by(commit_month, repo_short, author_latest_company) %>%
  summarise(num_authors=n_distinct(author_group),
            pct_authors=round(num_authors/first(total_authors), 2),
            author_latest_company_type=first(author_latest_company_type),
            author_company_employees=first(author_company_employees))



```

```{r fig-company-types-na, fig.height=12, fig.width=10}

ggplot(author_company_type_summary, aes(x=repo_short, y=pct_authors)) +
  geom_bar(aes(fill=author_latest_company_type), stat="identity", position="dodge") +
  scale_y_continuous(labels = percent, breaks=pretty_breaks()) +
  coord_flip() +
  theme_few() +
  labs(x="Repository", y="Authors (%)", title="Authors per Company Type - 2018 Jan + Feb") +
  guides(fill=guide_legend(title="Company Type"))
```

```{r fig-company-types, fig.height=12, fig.width=10}
ggplot(author_company_type_summary %>% filter(!is.na(author_latest_company_type)), 
       aes(x=repo_short, y=pct_authors)) +
  geom_bar(aes(fill=author_latest_company_type), stat="identity", position="dodge") +
  scale_y_continuous(labels = percent, breaks=pretty_breaks()) +
  coord_flip() +
  theme_few() +
  labs(x="Repository", y="Authors (%)", title="Authors per Company Type - 2018 Jan + Feb") +
  guides(fill=guide_legend(title="Company Type"))
```

```{r fig-companies, fig.height=12, fig.width=12}
ggplot(author_company_summary %>% 
         filter(author_latest_company_type %in% c("public", "private") & author_company_employees > 1), 
       aes(x=repo_short, y=pct_authors)) +
  geom_bar(aes(fill=author_latest_company), stat="identity", position="dodge") +
  scale_y_continuous(labels = percent, breaks=pretty_breaks()) +
  coord_flip() +
  theme_few() +
  labs(x="Repository", y="Authors (%)", title="Authors per Company - 2018 Jan + Feb") +
  guides(fill=guide_legend(title="Company", ncol=1)) +
  facet_wrap(~ commit_month)

ggplot(author_company_summary %>% 
         filter(author_latest_company_type %in% c("public")), 
       aes(x=repo_short, y=pct_authors)) +
  geom_bar(aes(fill=author_latest_company), stat="identity", position="dodge") +
  scale_y_continuous(labels = percent, breaks=pretty_breaks()) +
  coord_flip() +
  theme_few() +
  labs(x="Repository", y="Authors (%)", title="Authors per Company (Public) - 2018 Jan + Feb") +
  guides(fill=guide_legend(title="Company", ncol=1)) +
  facet_wrap(~ commit_month)
```





